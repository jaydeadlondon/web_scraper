import requests
from bs4 import BeautifulSoup
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes

# –ó–ê–ú–ï–ù–ò–¢–ï 'YOUR_TELEGRAM_BOT_TOKEN' –ù–ê –í–ê–® –¢–û–ö–ï–ù
TOKEN = 'YOUR_TELEGRAM_BOT_TOKEN'

user_langs = {}

def scrape_wikipedia(title, lang='en'):
    base_url = f"https://{lang}.wikipedia.org/wiki/{title}"
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0 Safari/537.36'
    }
    
    response = requests.get(base_url, headers=headers)
    
    if response.status_code != 200:
        if response.status_code == 404:
            return "‚ùå –°—Ç–∞—Ç—å—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ü—Ä–æ–≤–µ—Ä—å –Ω–∞–∑–≤–∞–Ω–∏–µ –∏ —è–∑—ã–∫."
        return f"–û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞: {response.status_code}"
    
    soup = BeautifulSoup(response.text, 'html.parser')
    
    try:
        heading = soup.find("h1", class_="firstHeading").get_text()
    except:
        heading = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
    
    try:
        paragraphs = soup.select(".mw-parser-output > p")
        
        first_paragraph_text = "–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Ç–µ–∫—Å—Ç."
        
        for p in paragraphs:
            text = p.get_text(strip=True)
            if text:
                first_paragraph_text = text
                break
    except Exception as e:
        first_paragraph_text = f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ —Ç–µ–∫—Å—Ç–∞: {e}"

    return f"üìò –°–¢–ê–¢–¨–Ø: {heading}\nüîó –°—Å—ã–ª–∫–∞: {base_url}\n\nüìù –ü–µ—Ä–≤—ã–π –∞–±–∑–∞—Ü:\n{first_paragraph_text}"

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.message.from_user.id
    user_langs[user_id] = 'en'
    await update.message.reply_text(
        '–ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –í–∏–∫–∏–ø–µ–¥–∏–∏.\n'
        '–ò—Å–ø–æ–ª—å–∑—É–π /set_lang ru –∏–ª–∏ /set_lang en, —á—Ç–æ–±—ã –≤—ã–±—Ä–∞—Ç—å —è–∑—ã–∫.\n'
        '–ó–∞—Ç–µ–º –ø—Ä–æ—Å—Ç–æ –æ—Ç–ø—Ä–∞–≤—å –º–Ω–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç—å–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞.'
    )

async def set_lang(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.message.from_user.id
    try:
        lang = context.args[0].lower()
        if lang in ['ru', 'en']:
            user_langs[user_id] = lang
            await update.message.reply_text(f"–Ø–∑—ã–∫ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –Ω–∞ {'—Ä—É—Å—Å–∫–∏–π' if lang == 'ru' else '–∞–Ω–≥–ª–∏–π—Å–∫–∏–π'}.")
        else:
            await update.message.reply_text("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏ 'ru' –∏–ª–∏ 'en'.")
    except (IndexError, ValueError):
        await update.message.reply_text("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: /set_lang <ru|en>")

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.message.from_user.id
    lang = user_langs.get(user_id, 'en')
    
    title = update.message.text.strip().replace(" ", "_")
    
    await update.message.reply_text("‚è≥ –ò–¥–µ—Ç –ø–æ–∏—Å–∫...")
    
    result = scrape_wikipedia(title, lang)
    
    await update.message.reply_text(result)

def main():
    if TOKEN == 'YOUR_TELEGRAM_BOT_TOKEN':
        print("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–º–µ–Ω–∏—Ç–µ 'YOUR_TELEGRAM_BOT_TOKEN' –Ω–∞ –≤–∞—à –Ω–∞—Å—Ç–æ—è—â–∏–π —Ç–æ–∫–µ–Ω –≤ —Ñ–∞–π–ª–µ scraper.py")
        return

    application = Application.builder().token(TOKEN).build()

    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("set_lang", set_lang))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

    application.run_polling()

if __name__ == "__main__":
    main()
